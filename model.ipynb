{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88e0c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be2d8ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9246591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "168ad04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "611f7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the data is already scaled, we only need to scale the Time and Amount columns\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "#we are using RobustScaler because it is less prone to Outliers\n",
    "\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
    "\n",
    "df.drop(['Time','Amount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d12b2ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>1.783274</td>\n",
       "      <td>-0.994983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.269825</td>\n",
       "      <td>-0.994983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>4.983721</td>\n",
       "      <td>-0.994972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>1.418291</td>\n",
       "      <td>-0.994972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>0.670579</td>\n",
       "      <td>-0.994960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024 -0.054952  ...  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Class  scaled_amount  scaled_time  \n",
       "0 -0.189115  0.133558 -0.021053      0       1.783274    -0.994983  \n",
       "1  0.125895 -0.008983  0.014724      0      -0.269825    -0.994983  \n",
       "2 -0.139097 -0.055353 -0.059752      0       4.983721    -0.994972  \n",
       "3 -0.221929  0.062723  0.061458      0       1.418291    -0.994972  \n",
       "4  0.502292  0.219422  0.215153      0       0.670579    -0.994960  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "759c0166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No frauds: 99.83\n",
      "Frauds: 0.17\n",
      "TRAIN: [ 30473  30496  31002 ... 284804 284805 284806] TEST: [    0     1     2 ... 57017 57018 57019]\n",
      "TRAIN: [     0      1      2 ... 284804 284805 284806] TEST: [ 30473  30496  31002 ... 113964 113965 113966]\n",
      "TRAIN: [     0      1      2 ... 284804 284805 284806] TEST: [ 81609  82400  83053 ... 170946 170947 170948]\n",
      "TRAIN: [     0      1      2 ... 284804 284805 284806] TEST: [150654 150660 150661 ... 227866 227867 227868]\n",
      "TRAIN: [     0      1      2 ... 227866 227867 227868] TEST: [212516 212644 213092 ... 284804 284805 284806]\n"
     ]
    }
   ],
   "source": [
    "#splitting the data before random under-sampling, because later on, we want to test our models on the original dataset\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "print(\"No frauds:\", round(df['Class'].value_counts()[0]/len(df) * 100, 2))\n",
    "print(\"Frauds:\", round(df['Class'].value_counts()[1]/len(df) * 100, 2))\n",
    "\n",
    "X = df.drop(['Class'], axis = 1)\n",
    "y = df['Class']\n",
    "      \n",
    "sss = StratifiedKFold()\n",
    "      \n",
    "for train_index, test_index in sss.split(X, y):\n",
    "     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "     OG_X_train, OG_X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "     OG_y_train, OG_y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "      \n",
    "# since we will be having X_train, X_test, y_train and y_test while splitting the undersampled data, hence we are using OG\n",
    "# as a suffix here to indicate the split of Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5699105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99827076 0.00172924]\n",
      "[0.99827952 0.00172048]\n"
     ]
    }
   ],
   "source": [
    "#checking if both the train and test sets are similarly distributed or not\n",
    "train_unique_label, train_counts_label = np.unique(OG_y_train, return_counts=True)\n",
    "test_unique_label, test_counts_label = np.unique(OG_y_test, return_counts=True)\n",
    "\n",
    "print(train_counts_label/ len(OG_y_train))\n",
    "print(test_counts_label/ len(OG_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ca54158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab638c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the above, we can observe that the data is imbalanced\n",
    "# to counter this, we have to perform random undersampling to balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc8a67fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling the data before random sampling\n",
    "\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de4c1196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199978</th>\n",
       "      <td>1.537917</td>\n",
       "      <td>-1.118107</td>\n",
       "      <td>-1.621756</td>\n",
       "      <td>0.394019</td>\n",
       "      <td>1.596456</td>\n",
       "      <td>4.205980</td>\n",
       "      <td>-0.999091</td>\n",
       "      <td>1.081079</td>\n",
       "      <td>0.898796</td>\n",
       "      <td>0.074676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.158783</td>\n",
       "      <td>0.175708</td>\n",
       "      <td>0.657188</td>\n",
       "      <td>-0.387432</td>\n",
       "      <td>-0.824595</td>\n",
       "      <td>0.052777</td>\n",
       "      <td>0.006628</td>\n",
       "      <td>0</td>\n",
       "      <td>2.558513</td>\n",
       "      <td>0.570190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110761</th>\n",
       "      <td>-2.676908</td>\n",
       "      <td>-0.254473</td>\n",
       "      <td>0.530839</td>\n",
       "      <td>1.589977</td>\n",
       "      <td>0.746987</td>\n",
       "      <td>-1.100256</td>\n",
       "      <td>-0.976151</td>\n",
       "      <td>0.733196</td>\n",
       "      <td>-0.789089</td>\n",
       "      <td>-0.317745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191596</td>\n",
       "      <td>-0.818140</td>\n",
       "      <td>0.191155</td>\n",
       "      <td>-0.483817</td>\n",
       "      <td>-0.368856</td>\n",
       "      <td>0.049521</td>\n",
       "      <td>-0.429318</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.272619</td>\n",
       "      <td>-0.149520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119005</th>\n",
       "      <td>1.065764</td>\n",
       "      <td>-0.670705</td>\n",
       "      <td>1.161876</td>\n",
       "      <td>0.329204</td>\n",
       "      <td>-1.391943</td>\n",
       "      <td>-0.136147</td>\n",
       "      <td>-0.807727</td>\n",
       "      <td>0.277254</td>\n",
       "      <td>1.483166</td>\n",
       "      <td>-0.455614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426470</td>\n",
       "      <td>0.139115</td>\n",
       "      <td>0.433351</td>\n",
       "      <td>-0.063696</td>\n",
       "      <td>0.954162</td>\n",
       "      <td>-0.037774</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0</td>\n",
       "      <td>0.376581</td>\n",
       "      <td>-0.110445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938</th>\n",
       "      <td>0.900987</td>\n",
       "      <td>-1.198726</td>\n",
       "      <td>0.391595</td>\n",
       "      <td>-2.028156</td>\n",
       "      <td>-1.079939</td>\n",
       "      <td>-0.037108</td>\n",
       "      <td>-0.545993</td>\n",
       "      <td>0.121461</td>\n",
       "      <td>2.091281</td>\n",
       "      <td>-1.600683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.895777</td>\n",
       "      <td>-0.339127</td>\n",
       "      <td>-0.215737</td>\n",
       "      <td>0.588879</td>\n",
       "      <td>-0.627919</td>\n",
       "      <td>0.091731</td>\n",
       "      <td>0.045328</td>\n",
       "      <td>0</td>\n",
       "      <td>2.070565</td>\n",
       "      <td>-0.953359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179816</th>\n",
       "      <td>-1.269472</td>\n",
       "      <td>1.664456</td>\n",
       "      <td>-0.726899</td>\n",
       "      <td>-0.875793</td>\n",
       "      <td>-0.047050</td>\n",
       "      <td>-0.755419</td>\n",
       "      <td>0.339618</td>\n",
       "      <td>0.647620</td>\n",
       "      <td>0.167416</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.619802</td>\n",
       "      <td>0.111026</td>\n",
       "      <td>-0.366117</td>\n",
       "      <td>-0.317659</td>\n",
       "      <td>0.131431</td>\n",
       "      <td>0.143599</td>\n",
       "      <td>-0.080555</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.169496</td>\n",
       "      <td>0.464738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "199978  1.537917 -1.118107 -1.621756  0.394019  1.596456  4.205980 -0.999091   \n",
       "110761 -2.676908 -0.254473  0.530839  1.589977  0.746987 -1.100256 -0.976151   \n",
       "119005  1.065764 -0.670705  1.161876  0.329204 -1.391943 -0.136147 -0.807727   \n",
       "3938    0.900987 -1.198726  0.391595 -2.028156 -1.079939 -0.037108 -0.545993   \n",
       "179816 -1.269472  1.664456 -0.726899 -0.875793 -0.047050 -0.755419  0.339618   \n",
       "\n",
       "              V8        V9       V10  ...       V22       V23       V24  \\\n",
       "199978  1.081079  0.898796  0.074676  ... -0.158783  0.175708  0.657188   \n",
       "110761  0.733196 -0.789089 -0.317745  ...  0.191596 -0.818140  0.191155   \n",
       "119005  0.277254  1.483166 -0.455614  ... -0.426470  0.139115  0.433351   \n",
       "3938    0.121461  2.091281 -1.600683  ...  0.895777 -0.339127 -0.215737   \n",
       "179816  0.647620  0.167416  0.458333  ... -0.619802  0.111026 -0.366117   \n",
       "\n",
       "             V25       V26       V27       V28  Class  scaled_amount  \\\n",
       "199978 -0.387432 -0.824595  0.052777  0.006628      0       2.558513   \n",
       "110761 -0.483817 -0.368856  0.049521 -0.429318      0      -0.272619   \n",
       "119005 -0.063696  0.954162 -0.037774  0.016976      0       0.376581   \n",
       "3938    0.588879 -0.627919  0.091731  0.045328      0       2.070565   \n",
       "179816 -0.317659  0.131431  0.143599 -0.080555      0      -0.169496   \n",
       "\n",
       "        scaled_time  \n",
       "199978     0.570190  \n",
       "110761    -0.149520  \n",
       "119005    -0.110445  \n",
       "3938      -0.953359  \n",
       "179816     0.464738  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b4722be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_df = df.loc[df['Class'] == 1]\n",
    "non_fraud_df = df.loc[df['Class'] == 0][:492]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72a81ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "normally_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "\n",
    "new_df = normally_distributed_df.sample(frac = 1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "252521a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69385</th>\n",
       "      <td>-1.126996</td>\n",
       "      <td>1.153055</td>\n",
       "      <td>1.397923</td>\n",
       "      <td>3.060821</td>\n",
       "      <td>1.015221</td>\n",
       "      <td>2.144787</td>\n",
       "      <td>-0.189868</td>\n",
       "      <td>-1.522753</td>\n",
       "      <td>-0.337669</td>\n",
       "      <td>0.895850</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.453575</td>\n",
       "      <td>0.792152</td>\n",
       "      <td>-0.772962</td>\n",
       "      <td>-1.240642</td>\n",
       "      <td>-0.112508</td>\n",
       "      <td>-0.253824</td>\n",
       "      <td>-0.367672</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.201495</td>\n",
       "      <td>-0.367638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177195</th>\n",
       "      <td>-1.073820</td>\n",
       "      <td>0.415616</td>\n",
       "      <td>-2.273977</td>\n",
       "      <td>1.536844</td>\n",
       "      <td>-0.758697</td>\n",
       "      <td>-1.670381</td>\n",
       "      <td>-2.377140</td>\n",
       "      <td>0.090370</td>\n",
       "      <td>0.004847</td>\n",
       "      <td>-2.776747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.863592</td>\n",
       "      <td>0.450743</td>\n",
       "      <td>-0.144228</td>\n",
       "      <td>-0.205609</td>\n",
       "      <td>-0.539073</td>\n",
       "      <td>0.503418</td>\n",
       "      <td>-0.237807</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.153706</td>\n",
       "      <td>0.450969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256651</th>\n",
       "      <td>-1.095244</td>\n",
       "      <td>-2.084863</td>\n",
       "      <td>-1.612821</td>\n",
       "      <td>-1.650286</td>\n",
       "      <td>-0.699437</td>\n",
       "      <td>0.513547</td>\n",
       "      <td>2.733292</td>\n",
       "      <td>-0.284772</td>\n",
       "      <td>-1.575088</td>\n",
       "      <td>-0.246401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.839513</td>\n",
       "      <td>1.446256</td>\n",
       "      <td>0.032023</td>\n",
       "      <td>-0.263077</td>\n",
       "      <td>-0.259623</td>\n",
       "      <td>-0.065248</td>\n",
       "      <td>0.265177</td>\n",
       "      <td>0</td>\n",
       "      <td>9.124572</td>\n",
       "      <td>0.858833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212644</th>\n",
       "      <td>-2.356348</td>\n",
       "      <td>1.746360</td>\n",
       "      <td>-6.374624</td>\n",
       "      <td>1.772205</td>\n",
       "      <td>-3.439294</td>\n",
       "      <td>1.457811</td>\n",
       "      <td>-0.362577</td>\n",
       "      <td>1.443791</td>\n",
       "      <td>-1.927359</td>\n",
       "      <td>-6.564659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621203</td>\n",
       "      <td>0.964817</td>\n",
       "      <td>-0.619437</td>\n",
       "      <td>-1.732613</td>\n",
       "      <td>0.108361</td>\n",
       "      <td>1.130828</td>\n",
       "      <td>0.415703</td>\n",
       "      <td>1</td>\n",
       "      <td>9.863900</td>\n",
       "      <td>0.637343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9179</th>\n",
       "      <td>-2.880042</td>\n",
       "      <td>5.225442</td>\n",
       "      <td>-11.063330</td>\n",
       "      <td>6.689951</td>\n",
       "      <td>-5.759924</td>\n",
       "      <td>-2.244031</td>\n",
       "      <td>-11.199975</td>\n",
       "      <td>4.014722</td>\n",
       "      <td>-3.429304</td>\n",
       "      <td>-11.561950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351102</td>\n",
       "      <td>0.795255</td>\n",
       "      <td>-0.778379</td>\n",
       "      <td>-1.646815</td>\n",
       "      <td>0.487539</td>\n",
       "      <td>1.427713</td>\n",
       "      <td>0.583172</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.293440</td>\n",
       "      <td>-0.840776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2         V3        V4        V5        V6  \\\n",
       "69385  -1.126996  1.153055   1.397923  3.060821  1.015221  2.144787   \n",
       "177195 -1.073820  0.415616  -2.273977  1.536844 -0.758697 -1.670381   \n",
       "256651 -1.095244 -2.084863  -1.612821 -1.650286 -0.699437  0.513547   \n",
       "212644 -2.356348  1.746360  -6.374624  1.772205 -3.439294  1.457811   \n",
       "9179   -2.880042  5.225442 -11.063330  6.689951 -5.759924 -2.244031   \n",
       "\n",
       "               V7        V8        V9        V10  ...       V22       V23  \\\n",
       "69385   -0.189868 -1.522753 -0.337669   0.895850  ... -0.453575  0.792152   \n",
       "177195  -2.377140  0.090370  0.004847  -2.776747  ...  0.863592  0.450743   \n",
       "256651   2.733292 -0.284772 -1.575088  -0.246401  ...  0.839513  1.446256   \n",
       "212644  -0.362577  1.443791 -1.927359  -6.564659  ...  0.621203  0.964817   \n",
       "9179   -11.199975  4.014722 -3.429304 -11.561950  ...  0.351102  0.795255   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Class  \\\n",
       "69385  -0.772962 -1.240642 -0.112508 -0.253824 -0.367672      0   \n",
       "177195 -0.144228 -0.205609 -0.539073  0.503418 -0.237807      1   \n",
       "256651  0.032023 -0.263077 -0.259623 -0.065248  0.265177      0   \n",
       "212644 -0.619437 -1.732613  0.108361  1.130828  0.415703      1   \n",
       "9179   -0.778379 -1.646815  0.487539  1.427713  0.583172      1   \n",
       "\n",
       "        scaled_amount  scaled_time  \n",
       "69385       -0.201495    -0.367638  \n",
       "177195      -0.153706     0.450969  \n",
       "256651       9.124572     0.858833  \n",
       "212644       9.863900     0.637343  \n",
       "9179        -0.293440    -0.840776  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "382174d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sub_sample_corr = new_df.corr()\n",
    "sns.heatmap(sub_sample_corr, cmap='coolwarm_r', annot_kws={'size':20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f7c47a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axes = plt.subplots(ncols=4, figsize=(20,4))\n",
    "\n",
    "# Negative Correlations with our Class (The lower our feature value the more likely it will be a fraud transaction)\n",
    "sns.boxplot(x=\"Class\", y=\"V17\", data=new_df, ax=axes[0])\n",
    "axes[0].set_title('V17 vs Class Negative Correlation')\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V14\", data=new_df, ax=axes[1])\n",
    "axes[1].set_title('V14 vs Class Negative Correlation')\n",
    "\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V12\", data=new_df, ax=axes[2])\n",
    "axes[2].set_title('V12 vs Class Negative Correlation')\n",
    "\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V10\", data=new_df, ax=axes[3])\n",
    "axes[3].set_title('V10 vs Class Negative Correlation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df5bee99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axes = plt.subplots(ncols=4, figsize=(20,4))\n",
    "\n",
    "# Positive correlations (The higher the feature the probability increases that it will be a fraud transaction)\n",
    "sns.boxplot(x=\"Class\", y=\"V11\", data=new_df, ax=axes[0])\n",
    "axes[0].set_title('V11 vs Class Positive Correlation')\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V4\", data=new_df, ax=axes[1])\n",
    "axes[1].set_title('V4 vs Class Positive Correlation')\n",
    "\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V2\", data=new_df, ax=axes[2])\n",
    "axes[2].set_title('V2 vs Class Positive Correlation')\n",
    "\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V19\", data=new_df, ax=axes[3])\n",
    "axes[3].set_title('V19 vs Class Positive Correlation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "13be13fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quartile 25: -9.692722964972386 | Quartile 75: -4.282820849486865\n",
      "iqr: 5.409902115485521\n",
      "Cut Off: 8.114853173228282\n",
      "V14 Lower: -17.807576138200666\n",
      "V14 Upper: 3.8320323237414167\n",
      "Feature V14 Outliers for Fraud Cases: 4\n",
      "V10 outliers:[-19.2143254902614, -18.0499976898594, -18.4937733551053, -18.8220867423816]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "V12 Lower: -17.3430371579634\n",
      "V12 Upper: 5.776973384895937\n",
      "V12 outliers: [-18.4311310279993, -18.6837146333443, -18.5536970096458, -18.0475965708216]\n",
      "Feature V12 Outliers for Fraud Cases: 4\n",
      "Number of Instances after outliers removal: 976\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "V10 Lower: -14.89885463232024\n",
      "V10 Upper: 4.92033495834214\n",
      "V10 outliers: [-22.1870885620007, -24.5882624372475, -18.9132433348732, -14.9246547735487, -15.3460988468775, -19.836148851696, -24.4031849699728, -22.1870885620007, -14.9246547735487, -17.1415136412892, -16.6496281595399, -16.7460441053944, -18.2711681738888, -20.9491915543611, -23.2282548357516, -15.2318333653018, -22.1870885620007, -15.5637913387301, -16.6011969664137, -16.3035376590131, -22.1870885620007, -15.1241628144947, -15.2399619587112, -16.2556117491401, -15.1237521803455, -15.2399619587112, -15.5637913387301]\n",
      "Feature V10 Outliers for Fraud Cases: 27\n",
      "Number of Instances after outliers removal: 948\n"
     ]
    }
   ],
   "source": [
    "# removing outliers from highly negatively correlated columns\n",
    "\n",
    "# # -----> V14 Removing Outliers (Highest Negative Correlated with Labels)\n",
    "v14_fraud = new_df['V14'].loc[new_df['Class'] == 1].values\n",
    "q25, q75 = np.percentile(v14_fraud, 25), np.percentile(v14_fraud, 75)\n",
    "print('Quartile 25: {} | Quartile 75: {}'.format(q25, q75))\n",
    "v14_iqr = q75 - q25\n",
    "print('iqr: {}'.format(v14_iqr))\n",
    "\n",
    "v14_cut_off = v14_iqr * 1.5\n",
    "v14_lower, v14_upper = q25 - v14_cut_off, q75 + v14_cut_off\n",
    "print('Cut Off: {}'.format(v14_cut_off))\n",
    "print('V14 Lower: {}'.format(v14_lower))\n",
    "print('V14 Upper: {}'.format(v14_upper))\n",
    "\n",
    "outliers = [x for x in v14_fraud if x < v14_lower or x > v14_upper]\n",
    "print('Feature V14 Outliers for Fraud Cases: {}'.format(len(outliers)))\n",
    "print('V10 outliers:{}'.format(outliers))\n",
    "\n",
    "new_df = new_df.drop(new_df[(new_df['V14'] > v14_upper) | (new_df['V14'] < v14_lower)].index)\n",
    "print('----' * 44)\n",
    "\n",
    "# -----> V12 removing outliers from fraud transactions\n",
    "v12_fraud = new_df['V12'].loc[new_df['Class'] == 1].values\n",
    "q25, q75 = np.percentile(v12_fraud, 25), np.percentile(v12_fraud, 75)\n",
    "v12_iqr = q75 - q25\n",
    "\n",
    "v12_cut_off = v12_iqr * 1.5\n",
    "v12_lower, v12_upper = q25 - v12_cut_off, q75 + v12_cut_off\n",
    "print('V12 Lower: {}'.format(v12_lower))\n",
    "print('V12 Upper: {}'.format(v12_upper))\n",
    "outliers = [x for x in v12_fraud if x < v12_lower or x > v12_upper]\n",
    "print('V12 outliers: {}'.format(outliers))\n",
    "print('Feature V12 Outliers for Fraud Cases: {}'.format(len(outliers)))\n",
    "new_df = new_df.drop(new_df[(new_df['V12'] > v12_upper) | (new_df['V12'] < v12_lower)].index)\n",
    "print('Number of Instances after outliers removal: {}'.format(len(new_df)))\n",
    "print('----' * 44)\n",
    "\n",
    "\n",
    "# Removing outliers V10 Feature\n",
    "v10_fraud = new_df['V10'].loc[new_df['Class'] == 1].values\n",
    "q25, q75 = np.percentile(v10_fraud, 25), np.percentile(v10_fraud, 75)\n",
    "v10_iqr = q75 - q25\n",
    "\n",
    "v10_cut_off = v10_iqr * 1.5\n",
    "v10_lower, v10_upper = q25 - v10_cut_off, q75 + v10_cut_off\n",
    "print('V10 Lower: {}'.format(v10_lower))\n",
    "print('V10 Upper: {}'.format(v10_upper))\n",
    "outliers = [x for x in v10_fraud if x < v10_lower or x > v10_upper]\n",
    "print('V10 outliers: {}'.format(outliers))\n",
    "print('Feature V10 Outliers for Fraud Cases: {}'.format(len(outliers)))\n",
    "new_df = new_df.drop(new_df[(new_df['V10'] > v10_upper) | (new_df['V10'] < v10_lower)].index)\n",
    "print('Number of Instances after outliers removal: {}'.format(len(new_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3fe44053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the undersampled dataset\n",
    "\n",
    "X = new_df.drop(['Class'], axis = 1)\n",
    "y = new_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "edcee0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e2e8b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:54:13] {2565} INFO - task = classification\n",
      "[flaml.automl: 08-30 11:54:13] {2567} INFO - Data split method: stratified\n",
      "[flaml.automl: 08-30 11:54:13] {2570} INFO - Evaluation method: cv\n",
      "[flaml.automl: 08-30 11:54:13] {2689} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl: 08-30 11:54:13] {2831} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl: 08-30 11:54:13] {3133} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 08-30 11:54:13] {3266} INFO - Estimated sufficient time budget=420s. Estimated necessary time budget=10s.\n",
      "[flaml.automl: 08-30 11:54:13] {3313} INFO -  at 0.2s,\testimator lgbm's best error=0.0726,\tbest estimator lgbm's best error=0.0726\n",
      "[flaml.automl: 08-30 11:54:13] {3133} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 08-30 11:54:13] {3313} INFO -  at 0.3s,\testimator lgbm's best error=0.0725,\tbest estimator lgbm's best error=0.0725\n",
      "[flaml.automl: 08-30 11:54:13] {3133} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 08-30 11:54:13] {3313} INFO -  at 0.3s,\testimator lgbm's best error=0.0725,\tbest estimator lgbm's best error=0.0725\n",
      "[flaml.automl: 08-30 11:54:13] {3133} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 08-30 11:54:13] {3313} INFO -  at 0.4s,\testimator lgbm's best error=0.0725,\tbest estimator lgbm's best error=0.0725\n",
      "[flaml.automl: 08-30 11:54:13] {3133} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl: 08-30 11:54:14] {3313} INFO -  at 0.5s,\testimator xgboost's best error=0.0712,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:14] {3133} INFO - iteration 5, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:14] {3313} INFO -  at 0.5s,\testimator extra_tree's best error=0.1042,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:14] {3133} INFO - iteration 6, current learner rf\n",
      "[flaml.automl: 08-30 11:54:14] {3313} INFO -  at 0.6s,\testimator rf's best error=0.0765,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:14] {3133} INFO - iteration 7, current learner rf\n",
      "[flaml.automl: 08-30 11:54:14] {3313} INFO -  at 0.7s,\testimator rf's best error=0.0765,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:14] {3133} INFO - iteration 8, current learner rf\n",
      "[flaml.automl: 08-30 11:54:14] {3313} INFO -  at 0.8s,\testimator rf's best error=0.0765,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:14] {3133} INFO - iteration 9, current learner rf\n",
      "[flaml.automl: 08-30 11:54:14] {3313} INFO -  at 0.9s,\testimator rf's best error=0.0752,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:14] {3133} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl: 08-30 11:54:14] {3313} INFO -  at 0.9s,\testimator xgboost's best error=0.0712,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:14] {3133} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 08-30 11:54:14] {3313} INFO -  at 1.0s,\testimator xgboost's best error=0.0712,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:14] {3133} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:14] {3313} INFO -  at 1.1s,\testimator extra_tree's best error=0.0857,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:14] {3133} INFO - iteration 13, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:14] {3313} INFO -  at 1.2s,\testimator extra_tree's best error=0.0857,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:14] {3133} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl: 08-30 11:54:14] {3313} INFO -  at 1.3s,\testimator xgboost's best error=0.0712,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:14] {3133} INFO - iteration 15, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:15] {3313} INFO -  at 1.4s,\testimator extra_tree's best error=0.0857,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:15] {3133} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl: 08-30 11:54:15] {3313} INFO -  at 1.5s,\testimator xgboost's best error=0.0712,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:15] {3133} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:15] {3313} INFO -  at 1.6s,\testimator extra_tree's best error=0.0752,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:15] {3133} INFO - iteration 18, current learner rf\n",
      "[flaml.automl: 08-30 11:54:15] {3313} INFO -  at 1.7s,\testimator rf's best error=0.0752,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:15] {3133} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:15] {3313} INFO -  at 1.8s,\testimator extra_tree's best error=0.0752,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:15] {3133} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl: 08-30 11:54:15] {3313} INFO -  at 1.9s,\testimator xgboost's best error=0.0712,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:15] {3133} INFO - iteration 21, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:15] {3313} INFO -  at 2.0s,\testimator extra_tree's best error=0.0739,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:15] {3133} INFO - iteration 22, current learner rf\n",
      "[flaml.automl: 08-30 11:54:15] {3313} INFO -  at 2.1s,\testimator rf's best error=0.0752,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:15] {3133} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl: 08-30 11:54:15] {3313} INFO -  at 2.2s,\testimator xgboost's best error=0.0712,\tbest estimator xgboost's best error=0.0712\n",
      "[flaml.automl: 08-30 11:54:15] {3133} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:15] {3313} INFO -  at 2.4s,\testimator extra_tree's best error=0.0673,\tbest estimator extra_tree's best error=0.0673\n",
      "[flaml.automl: 08-30 11:54:15] {3133} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:16] {3313} INFO -  at 2.5s,\testimator extra_tree's best error=0.0673,\tbest estimator extra_tree's best error=0.0673\n",
      "[flaml.automl: 08-30 11:54:16] {3133} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:16] {3313} INFO -  at 2.6s,\testimator extra_tree's best error=0.0673,\tbest estimator extra_tree's best error=0.0673\n",
      "[flaml.automl: 08-30 11:54:16] {3133} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:16] {3313} INFO -  at 2.7s,\testimator extra_tree's best error=0.0646,\tbest estimator extra_tree's best error=0.0646\n",
      "[flaml.automl: 08-30 11:54:16] {3133} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:16] {3313} INFO -  at 2.8s,\testimator extra_tree's best error=0.0646,\tbest estimator extra_tree's best error=0.0646\n",
      "[flaml.automl: 08-30 11:54:16] {3133} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:16] {3313} INFO -  at 2.9s,\testimator extra_tree's best error=0.0646,\tbest estimator extra_tree's best error=0.0646\n",
      "[flaml.automl: 08-30 11:54:16] {3133} INFO - iteration 30, current learner xgboost\n",
      "[flaml.automl: 08-30 11:54:16] {3313} INFO -  at 3.0s,\testimator xgboost's best error=0.0712,\tbest estimator extra_tree's best error=0.0646\n",
      "[flaml.automl: 08-30 11:54:16] {3133} INFO - iteration 31, current learner xgboost\n",
      "[flaml.automl: 08-30 11:54:16] {3313} INFO -  at 3.1s,\testimator xgboost's best error=0.0712,\tbest estimator extra_tree's best error=0.0646\n",
      "[flaml.automl: 08-30 11:54:16] {3133} INFO - iteration 32, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:16] {3313} INFO -  at 3.2s,\testimator extra_tree's best error=0.0646,\tbest estimator extra_tree's best error=0.0646\n",
      "[flaml.automl: 08-30 11:54:16] {3133} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:16] {3313} INFO -  at 3.4s,\testimator extra_tree's best error=0.0646,\tbest estimator extra_tree's best error=0.0646\n",
      "[flaml.automl: 08-30 11:54:16] {3133} INFO - iteration 34, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:17] {3313} INFO -  at 3.5s,\testimator extra_tree's best error=0.0646,\tbest estimator extra_tree's best error=0.0646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:54:17] {3133} INFO - iteration 35, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:17] {3313} INFO -  at 3.6s,\testimator extra_tree's best error=0.0646,\tbest estimator extra_tree's best error=0.0646\n",
      "[flaml.automl: 08-30 11:54:17] {3133} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:17] {3313} INFO -  at 3.7s,\testimator extra_tree's best error=0.0646,\tbest estimator extra_tree's best error=0.0646\n",
      "[flaml.automl: 08-30 11:54:17] {3133} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:17] {3313} INFO -  at 3.8s,\testimator extra_tree's best error=0.0607,\tbest estimator extra_tree's best error=0.0607\n",
      "[flaml.automl: 08-30 11:54:17] {3133} INFO - iteration 38, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:17] {3313} INFO -  at 4.0s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:17] {3133} INFO - iteration 39, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:17] {3313} INFO -  at 4.2s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:17] {3133} INFO - iteration 40, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:17] {3313} INFO -  at 4.3s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:17] {3133} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:18] {3313} INFO -  at 4.5s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:18] {3133} INFO - iteration 42, current learner rf\n",
      "[flaml.automl: 08-30 11:54:18] {3313} INFO -  at 4.6s,\testimator rf's best error=0.0752,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:18] {3133} INFO - iteration 43, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:18] {3313} INFO -  at 4.8s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:18] {3133} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:18] {3313} INFO -  at 4.9s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:18] {3133} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:18] {3313} INFO -  at 5.1s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:18] {3133} INFO - iteration 46, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:18] {3313} INFO -  at 5.2s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:18] {3133} INFO - iteration 47, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:18] {3313} INFO -  at 5.4s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:18] {3133} INFO - iteration 48, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:19] {3313} INFO -  at 5.5s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:19] {3133} INFO - iteration 49, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:19] {3313} INFO -  at 5.6s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:19] {3133} INFO - iteration 50, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:19] {3313} INFO -  at 5.8s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:19] {3133} INFO - iteration 51, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:19] {3313} INFO -  at 5.9s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:19] {3133} INFO - iteration 52, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:19] {3313} INFO -  at 6.1s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:19] {3133} INFO - iteration 53, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:19] {3313} INFO -  at 6.2s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:19] {3133} INFO - iteration 54, current learner rf\n",
      "[flaml.automl: 08-30 11:54:19] {3313} INFO -  at 6.3s,\testimator rf's best error=0.0752,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:19] {3133} INFO - iteration 55, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:20] {3313} INFO -  at 6.5s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:20] {3133} INFO - iteration 56, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:20] {3313} INFO -  at 6.7s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:20] {3133} INFO - iteration 57, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:20] {3313} INFO -  at 6.8s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:20] {3133} INFO - iteration 58, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:20] {3313} INFO -  at 6.9s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:20] {3133} INFO - iteration 59, current learner rf\n",
      "[flaml.automl: 08-30 11:54:20] {3313} INFO -  at 7.0s,\testimator rf's best error=0.0752,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:20] {3133} INFO - iteration 60, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:20] {3313} INFO -  at 7.2s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:20] {3133} INFO - iteration 61, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:20] {3313} INFO -  at 7.4s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:20] {3133} INFO - iteration 62, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:21] {3313} INFO -  at 7.5s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:21] {3133} INFO - iteration 63, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:21] {3313} INFO -  at 7.7s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:21] {3133} INFO - iteration 64, current learner xgb_limitdepth\n",
      "[flaml.automl: 08-30 11:54:21] {3313} INFO -  at 7.8s,\testimator xgb_limitdepth's best error=0.0673,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:21] {3133} INFO - iteration 65, current learner xgb_limitdepth\n",
      "[flaml.automl: 08-30 11:54:21] {3313} INFO -  at 7.9s,\testimator xgb_limitdepth's best error=0.0659,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:21] {3133} INFO - iteration 66, current learner xgb_limitdepth\n",
      "[flaml.automl: 08-30 11:54:21] {3313} INFO -  at 8.0s,\testimator xgb_limitdepth's best error=0.0646,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:21] {3133} INFO - iteration 67, current learner xgb_limitdepth\n",
      "[flaml.automl: 08-30 11:54:21] {3313} INFO -  at 8.1s,\testimator xgb_limitdepth's best error=0.0646,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:21] {3133} INFO - iteration 68, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:21] {3313} INFO -  at 8.2s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:21] {3133} INFO - iteration 69, current learner rf\n",
      "[flaml.automl: 08-30 11:54:21] {3313} INFO -  at 8.3s,\testimator rf's best error=0.0752,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:21] {3133} INFO - iteration 70, current learner xgb_limitdepth\n",
      "[flaml.automl: 08-30 11:54:22] {3313} INFO -  at 8.4s,\testimator xgb_limitdepth's best error=0.0646,\tbest estimator extra_tree's best error=0.0593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:54:22] {3133} INFO - iteration 71, current learner xgb_limitdepth\n",
      "[flaml.automl: 08-30 11:54:22] {3313} INFO -  at 8.5s,\testimator xgb_limitdepth's best error=0.0646,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:22] {3133} INFO - iteration 72, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:22] {3313} INFO -  at 8.7s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:22] {3133} INFO - iteration 73, current learner xgb_limitdepth\n",
      "[flaml.automl: 08-30 11:54:22] {3313} INFO -  at 8.8s,\testimator xgb_limitdepth's best error=0.0646,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:22] {3133} INFO - iteration 74, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:22] {3313} INFO -  at 9.0s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:22] {3133} INFO - iteration 75, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:22] {3313} INFO -  at 9.1s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:22] {3133} INFO - iteration 76, current learner rf\n",
      "[flaml.automl: 08-30 11:54:22] {3313} INFO -  at 9.3s,\testimator rf's best error=0.0738,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:22] {3133} INFO - iteration 77, current learner rf\n",
      "[flaml.automl: 08-30 11:54:22] {3313} INFO -  at 9.3s,\testimator rf's best error=0.0738,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:22] {3133} INFO - iteration 78, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:23] {3313} INFO -  at 9.5s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:23] {3133} INFO - iteration 79, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:23] {3313} INFO -  at 9.6s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:23] {3133} INFO - iteration 80, current learner rf\n",
      "[flaml.automl: 08-30 11:54:23] {3313} INFO -  at 9.7s,\testimator rf's best error=0.0620,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:23] {3133} INFO - iteration 81, current learner rf\n",
      "[flaml.automl: 08-30 11:54:23] {3313} INFO -  at 9.8s,\testimator rf's best error=0.0620,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:23] {3133} INFO - iteration 82, current learner rf\n",
      "[flaml.automl: 08-30 11:54:23] {3313} INFO -  at 10.0s,\testimator rf's best error=0.0620,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:23] {3133} INFO - iteration 83, current learner rf\n",
      "[flaml.automl: 08-30 11:54:23] {3313} INFO -  at 10.1s,\testimator rf's best error=0.0620,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:23] {3133} INFO - iteration 84, current learner rf\n",
      "[flaml.automl: 08-30 11:54:23] {3313} INFO -  at 10.3s,\testimator rf's best error=0.0620,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:23] {3133} INFO - iteration 85, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:24] {3313} INFO -  at 10.4s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:24] {3133} INFO - iteration 86, current learner rf\n",
      "[flaml.automl: 08-30 11:54:24] {3313} INFO -  at 10.5s,\testimator rf's best error=0.0620,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:24] {3133} INFO - iteration 87, current learner rf\n",
      "[flaml.automl: 08-30 11:54:24] {3313} INFO -  at 10.7s,\testimator rf's best error=0.0620,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:24] {3133} INFO - iteration 88, current learner rf\n",
      "[flaml.automl: 08-30 11:54:24] {3313} INFO -  at 10.9s,\testimator rf's best error=0.0620,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:24] {3133} INFO - iteration 89, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:24] {3313} INFO -  at 11.0s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:24] {3133} INFO - iteration 90, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:24] {3313} INFO -  at 11.1s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:24] {3133} INFO - iteration 91, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:24] {3313} INFO -  at 11.3s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:24] {3133} INFO - iteration 92, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:25] {3313} INFO -  at 11.4s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:25] {3133} INFO - iteration 93, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:25] {3313} INFO -  at 11.6s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:25] {3133} INFO - iteration 94, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:25] {3313} INFO -  at 11.7s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:25] {3133} INFO - iteration 95, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:25] {3313} INFO -  at 11.9s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:25] {3133} INFO - iteration 96, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:25] {3313} INFO -  at 12.0s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:25] {3133} INFO - iteration 97, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:25] {3313} INFO -  at 12.2s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:25] {3133} INFO - iteration 98, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:25] {3313} INFO -  at 12.3s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:25] {3133} INFO - iteration 99, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:26] {3313} INFO -  at 12.5s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:26] {3133} INFO - iteration 100, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:26] {3313} INFO -  at 12.6s,\testimator extra_tree's best error=0.0593,\tbest estimator extra_tree's best error=0.0593\n",
      "[flaml.automl: 08-30 11:54:26] {3133} INFO - iteration 101, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:26] {3313} INFO -  at 12.7s,\testimator extra_tree's best error=0.0567,\tbest estimator extra_tree's best error=0.0567\n",
      "[flaml.automl: 08-30 11:54:26] {3133} INFO - iteration 102, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:26] {3313} INFO -  at 12.9s,\testimator extra_tree's best error=0.0567,\tbest estimator extra_tree's best error=0.0567\n",
      "[flaml.automl: 08-30 11:54:26] {3133} INFO - iteration 103, current learner lgbm\n",
      "[flaml.automl: 08-30 11:54:26] {3313} INFO -  at 12.9s,\testimator lgbm's best error=0.0725,\tbest estimator extra_tree's best error=0.0567\n",
      "[flaml.automl: 08-30 11:54:26] {3133} INFO - iteration 104, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:26] {3313} INFO -  at 13.1s,\testimator extra_tree's best error=0.0567,\tbest estimator extra_tree's best error=0.0567\n",
      "[flaml.automl: 08-30 11:54:26] {3133} INFO - iteration 105, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:26] {3313} INFO -  at 13.2s,\testimator extra_tree's best error=0.0567,\tbest estimator extra_tree's best error=0.0567\n",
      "[flaml.automl: 08-30 11:54:26] {3133} INFO - iteration 106, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:26] {3313} INFO -  at 13.3s,\testimator extra_tree's best error=0.0567,\tbest estimator extra_tree's best error=0.0567\n",
      "[flaml.automl: 08-30 11:54:26] {3133} INFO - iteration 107, current learner extra_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:54:27] {3313} INFO -  at 13.5s,\testimator extra_tree's best error=0.0567,\tbest estimator extra_tree's best error=0.0567\n",
      "[flaml.automl: 08-30 11:54:27] {3133} INFO - iteration 108, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:27] {3313} INFO -  at 13.6s,\testimator extra_tree's best error=0.0567,\tbest estimator extra_tree's best error=0.0567\n",
      "[flaml.automl: 08-30 11:54:27] {3133} INFO - iteration 109, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:27] {3313} INFO -  at 13.8s,\testimator extra_tree's best error=0.0567,\tbest estimator extra_tree's best error=0.0567\n",
      "[flaml.automl: 08-30 11:54:27] {3133} INFO - iteration 110, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:27] {3313} INFO -  at 13.9s,\testimator extra_tree's best error=0.0567,\tbest estimator extra_tree's best error=0.0567\n",
      "[flaml.automl: 08-30 11:54:27] {3133} INFO - iteration 111, current learner lgbm\n",
      "[flaml.automl: 08-30 11:54:27] {3313} INFO -  at 13.9s,\testimator lgbm's best error=0.0725,\tbest estimator extra_tree's best error=0.0567\n",
      "[flaml.automl: 08-30 11:54:27] {3133} INFO - iteration 112, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:27] {3313} INFO -  at 14.1s,\testimator extra_tree's best error=0.0567,\tbest estimator extra_tree's best error=0.0567\n",
      "[flaml.automl: 08-30 11:54:27] {3133} INFO - iteration 113, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:27] {3313} INFO -  at 14.2s,\testimator extra_tree's best error=0.0567,\tbest estimator extra_tree's best error=0.0567\n",
      "[flaml.automl: 08-30 11:54:27] {3133} INFO - iteration 114, current learner xgb_limitdepth\n",
      "[flaml.automl: 08-30 11:54:27] {3313} INFO -  at 14.3s,\testimator xgb_limitdepth's best error=0.0646,\tbest estimator extra_tree's best error=0.0567\n",
      "[flaml.automl: 08-30 11:54:27] {3133} INFO - iteration 115, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:28] {3313} INFO -  at 14.5s,\testimator extra_tree's best error=0.0567,\tbest estimator extra_tree's best error=0.0567\n",
      "[flaml.automl: 08-30 11:54:28] {3133} INFO - iteration 116, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:28] {3313} INFO -  at 14.6s,\testimator extra_tree's best error=0.0567,\tbest estimator extra_tree's best error=0.0567\n",
      "[flaml.automl: 08-30 11:54:28] {3133} INFO - iteration 117, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:28] {3313} INFO -  at 14.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:28] {3133} INFO - iteration 118, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:28] {3313} INFO -  at 14.9s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:28] {3133} INFO - iteration 119, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:28] {3313} INFO -  at 15.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:28] {3133} INFO - iteration 120, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:28] {3313} INFO -  at 15.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:28] {3133} INFO - iteration 121, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:28] {3313} INFO -  at 15.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:28] {3133} INFO - iteration 122, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:28] {3313} INFO -  at 15.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:28] {3133} INFO - iteration 123, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:29] {3313} INFO -  at 15.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:29] {3133} INFO - iteration 124, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:29] {3313} INFO -  at 15.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:29] {3133} INFO - iteration 125, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:29] {3313} INFO -  at 15.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:29] {3133} INFO - iteration 126, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:29] {3313} INFO -  at 15.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:29] {3133} INFO - iteration 127, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:29] {3313} INFO -  at 16.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:29] {3133} INFO - iteration 128, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:29] {3313} INFO -  at 16.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:29] {3133} INFO - iteration 129, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:29] {3313} INFO -  at 16.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:29] {3133} INFO - iteration 130, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:29] {3313} INFO -  at 16.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:29] {3133} INFO - iteration 131, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:30] {3313} INFO -  at 16.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:30] {3133} INFO - iteration 132, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:30] {3313} INFO -  at 16.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:30] {3133} INFO - iteration 133, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:30] {3313} INFO -  at 16.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:30] {3133} INFO - iteration 134, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:30] {3313} INFO -  at 16.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:30] {3133} INFO - iteration 135, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:30] {3313} INFO -  at 16.9s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:30] {3133} INFO - iteration 136, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:30] {3313} INFO -  at 17.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:30] {3133} INFO - iteration 137, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:30] {3313} INFO -  at 17.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:30] {3133} INFO - iteration 138, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:30] {3313} INFO -  at 17.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:30] {3133} INFO - iteration 139, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:30] {3313} INFO -  at 17.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:30] {3133} INFO - iteration 140, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:31] {3313} INFO -  at 17.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:31] {3133} INFO - iteration 141, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:31] {3313} INFO -  at 17.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:31] {3133} INFO - iteration 142, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:31] {3313} INFO -  at 17.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:54:31] {3133} INFO - iteration 143, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:31] {3313} INFO -  at 17.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:31] {3133} INFO - iteration 144, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:31] {3313} INFO -  at 18.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:31] {3133} INFO - iteration 145, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:31] {3313} INFO -  at 18.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:31] {3133} INFO - iteration 146, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:31] {3313} INFO -  at 18.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:31] {3133} INFO - iteration 147, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:31] {3313} INFO -  at 18.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:31] {3133} INFO - iteration 148, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:32] {3313} INFO -  at 18.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:32] {3133} INFO - iteration 149, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:32] {3313} INFO -  at 18.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:32] {3133} INFO - iteration 150, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:32] {3313} INFO -  at 18.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:32] {3133} INFO - iteration 151, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:32] {3313} INFO -  at 18.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:32] {3133} INFO - iteration 152, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:32] {3313} INFO -  at 18.9s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:32] {3133} INFO - iteration 153, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:32] {3313} INFO -  at 19.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:32] {3133} INFO - iteration 154, current learner lgbm\n",
      "[flaml.automl: 08-30 11:54:32] {3313} INFO -  at 19.0s,\testimator lgbm's best error=0.0725,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:32] {3133} INFO - iteration 155, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:32] {3313} INFO -  at 19.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:32] {3133} INFO - iteration 156, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:32] {3313} INFO -  at 19.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:32] {3133} INFO - iteration 157, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:33] {3313} INFO -  at 19.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:33] {3133} INFO - iteration 158, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:33] {3313} INFO -  at 19.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:33] {3133} INFO - iteration 159, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:33] {3313} INFO -  at 19.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:33] {3133} INFO - iteration 160, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:33] {3313} INFO -  at 19.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:33] {3133} INFO - iteration 161, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:33] {3313} INFO -  at 19.9s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:33] {3133} INFO - iteration 162, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:33] {3313} INFO -  at 20.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:33] {3133} INFO - iteration 163, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:33] {3313} INFO -  at 20.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:33] {3133} INFO - iteration 164, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:33] {3313} INFO -  at 20.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:33] {3133} INFO - iteration 165, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:34] {3313} INFO -  at 20.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:34] {3133} INFO - iteration 166, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:34] {3313} INFO -  at 20.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:34] {3133} INFO - iteration 167, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:34] {3313} INFO -  at 20.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:34] {3133} INFO - iteration 168, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:34] {3313} INFO -  at 20.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:34] {3133} INFO - iteration 169, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:34] {3313} INFO -  at 20.9s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:34] {3133} INFO - iteration 170, current learner lgbm\n",
      "[flaml.automl: 08-30 11:54:34] {3313} INFO -  at 20.9s,\testimator lgbm's best error=0.0725,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:34] {3133} INFO - iteration 171, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:34] {3313} INFO -  at 21.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:34] {3133} INFO - iteration 172, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:34] {3313} INFO -  at 21.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:34] {3133} INFO - iteration 173, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:34] {3313} INFO -  at 21.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:34] {3133} INFO - iteration 174, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:34] {3313} INFO -  at 21.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:34] {3133} INFO - iteration 175, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:35] {3313} INFO -  at 21.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:35] {3133} INFO - iteration 176, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:35] {3313} INFO -  at 21.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:35] {3133} INFO - iteration 177, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:35] {3313} INFO -  at 21.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:35] {3133} INFO - iteration 178, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:35] {3313} INFO -  at 21.9s,\testimator lrl1's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:35] {3133} INFO - iteration 179, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:35] {3313} INFO -  at 22.1s,\testimator lrl1's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:35] {3133} INFO - iteration 180, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:35] {3313} INFO -  at 22.2s,\testimator lrl1's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:35] {3133} INFO - iteration 181, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:35] {3313} INFO -  at 22.4s,\testimator lrl1's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:35] {3133} INFO - iteration 182, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:36] {3313} INFO -  at 22.6s,\testimator lrl1's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:36] {3133} INFO - iteration 183, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:36] {3313} INFO -  at 22.7s,\testimator lrl1's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:36] {3133} INFO - iteration 184, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:36] {3313} INFO -  at 22.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:36] {3133} INFO - iteration 185, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:36] {3313} INFO -  at 23.0s,\testimator lrl1's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:36] {3133} INFO - iteration 186, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:36] {3313} INFO -  at 23.2s,\testimator lrl1's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:54:36] {3133} INFO - iteration 187, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:36] {3313} INFO -  at 23.3s,\testimator lrl1's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:36] {3133} INFO - iteration 188, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:37] {3313} INFO -  at 23.5s,\testimator lrl1's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:37] {3133} INFO - iteration 189, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:37] {3313} INFO -  at 23.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:37] {3133} INFO - iteration 190, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:37] {3313} INFO -  at 23.8s,\testimator lrl1's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:37] {3133} INFO - iteration 191, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:37] {3313} INFO -  at 23.9s,\testimator lrl1's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:37] {3133} INFO - iteration 192, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:37] {3313} INFO -  at 24.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:37] {3133} INFO - iteration 193, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:37] {3313} INFO -  at 24.2s,\testimator lrl1's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:37] {3133} INFO - iteration 194, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:37] {3313} INFO -  at 24.4s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:37] {3133} INFO - iteration 195, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:38] {3313} INFO -  at 24.5s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:38] {3133} INFO - iteration 196, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:38] {3313} INFO -  at 24.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:38] {3133} INFO - iteration 197, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:38] {3313} INFO -  at 24.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:38] {3133} INFO - iteration 198, current learner lrl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:38] {3313} INFO -  at 24.9s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:38] {3133} INFO - iteration 199, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:38] {3313} INFO -  at 25.1s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:38] {3133} INFO - iteration 200, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:38] {3313} INFO -  at 25.3s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:38] {3133} INFO - iteration 201, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:39] {3313} INFO -  at 25.4s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:39] {3133} INFO - iteration 202, current learner lgbm\n",
      "[flaml.automl: 08-30 11:54:39] {3313} INFO -  at 25.5s,\testimator lgbm's best error=0.0725,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:39] {3133} INFO - iteration 203, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:39] {3313} INFO -  at 25.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:39] {3133} INFO - iteration 204, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:39] {3313} INFO -  at 25.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:39] {3133} INFO - iteration 205, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:39] {3313} INFO -  at 25.8s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:39] {3133} INFO - iteration 206, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:39] {3313} INFO -  at 26.0s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:39] {3133} INFO - iteration 207, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:39] {3313} INFO -  at 26.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:39] {3133} INFO - iteration 208, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:39] {3313} INFO -  at 26.3s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:39] {3133} INFO - iteration 209, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:40] {3313} INFO -  at 26.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:54:40] {3133} INFO - iteration 210, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:40] {3313} INFO -  at 26.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:40] {3133} INFO - iteration 211, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:40] {3313} INFO -  at 26.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:40] {3133} INFO - iteration 212, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:40] {3313} INFO -  at 26.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:40] {3133} INFO - iteration 213, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:40] {3313} INFO -  at 26.9s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:40] {3133} INFO - iteration 214, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:40] {3313} INFO -  at 27.1s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:40] {3133} INFO - iteration 215, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:40] {3313} INFO -  at 27.2s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:40] {3133} INFO - iteration 216, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:40] {3313} INFO -  at 27.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:40] {3133} INFO - iteration 217, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:41] {3313} INFO -  at 27.5s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:41] {3133} INFO - iteration 218, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:41] {3313} INFO -  at 27.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:41] {3133} INFO - iteration 219, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:41] {3313} INFO -  at 27.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:41] {3133} INFO - iteration 220, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:41] {3313} INFO -  at 27.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:41] {3133} INFO - iteration 221, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:41] {3313} INFO -  at 28.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:41] {3133} INFO - iteration 222, current learner xgboost\n",
      "[flaml.automl: 08-30 11:54:41] {3313} INFO -  at 28.0s,\testimator xgboost's best error=0.0712,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:41] {3133} INFO - iteration 223, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:41] {3313} INFO -  at 28.2s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:41] {3133} INFO - iteration 224, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:41] {3313} INFO -  at 28.4s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:41] {3133} INFO - iteration 225, current learner lgbm\n",
      "[flaml.automl: 08-30 11:54:42] {3313} INFO -  at 28.4s,\testimator lgbm's best error=0.0725,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:42] {3133} INFO - iteration 226, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:42] {3313} INFO -  at 28.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:42] {3133} INFO - iteration 227, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:42] {3313} INFO -  at 28.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:42] {3133} INFO - iteration 228, current learner extra_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:54:42] {3313} INFO -  at 28.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:42] {3133} INFO - iteration 229, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:42] {3313} INFO -  at 28.9s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:42] {3133} INFO - iteration 230, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:42] {3313} INFO -  at 29.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:42] {3133} INFO - iteration 231, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:42] {3313} INFO -  at 29.2s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:42] {3133} INFO - iteration 232, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:42] {3313} INFO -  at 29.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:42] {3133} INFO - iteration 233, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:43] {3313} INFO -  at 29.4s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:43] {3133} INFO - iteration 234, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:43] {3313} INFO -  at 29.6s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:43] {3133} INFO - iteration 235, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:43] {3313} INFO -  at 29.7s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:43] {3133} INFO - iteration 236, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:43] {3313} INFO -  at 29.9s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:43] {3133} INFO - iteration 237, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:43] {3313} INFO -  at 29.9s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:43] {3133} INFO - iteration 238, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:43] {3313} INFO -  at 30.1s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:43] {3133} INFO - iteration 239, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:43] {3313} INFO -  at 30.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:43] {3133} INFO - iteration 240, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:43] {3313} INFO -  at 30.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:43] {3133} INFO - iteration 241, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:44] {3313} INFO -  at 30.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:44] {3133} INFO - iteration 242, current learner lgbm\n",
      "[flaml.automl: 08-30 11:54:44] {3313} INFO -  at 30.5s,\testimator lgbm's best error=0.0725,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:44] {3133} INFO - iteration 243, current learner extra_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:54:44] {3313} INFO -  at 30.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:44] {3133} INFO - iteration 244, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:44] {3313} INFO -  at 30.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:44] {3133} INFO - iteration 245, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:44] {3313} INFO -  at 30.9s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:44] {3133} INFO - iteration 246, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:44] {3313} INFO -  at 31.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:44] {3133} INFO - iteration 247, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:44] {3313} INFO -  at 31.2s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:44] {3133} INFO - iteration 248, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:44] {3313} INFO -  at 31.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:44] {3133} INFO - iteration 249, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:44] {3313} INFO -  at 31.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:44] {3133} INFO - iteration 250, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:45] {3313} INFO -  at 31.5s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:45] {3133} INFO - iteration 251, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:45] {3313} INFO -  at 31.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:45] {3133} INFO - iteration 252, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:45] {3313} INFO -  at 31.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:45] {3133} INFO - iteration 253, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:45] {3313} INFO -  at 31.9s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:45] {3133} INFO - iteration 254, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:45] {3313} INFO -  at 32.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:45] {3133} INFO - iteration 255, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:45] {3313} INFO -  at 32.1s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:45] {3133} INFO - iteration 256, current learner lgbm\n",
      "[flaml.automl: 08-30 11:54:45] {3313} INFO -  at 32.2s,\testimator lgbm's best error=0.0725,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:45] {3133} INFO - iteration 257, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:45] {3313} INFO -  at 32.4s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:45] {3133} INFO - iteration 258, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:46] {3313} INFO -  at 32.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:46] {3133} INFO - iteration 259, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:46] {3313} INFO -  at 32.6s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:54:46] {3133} INFO - iteration 260, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:46] {3313} INFO -  at 32.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:46] {3133} INFO - iteration 261, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:46] {3313} INFO -  at 32.9s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:46] {3133} INFO - iteration 262, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:46] {3313} INFO -  at 33.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:46] {3133} INFO - iteration 263, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:46] {3313} INFO -  at 33.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:46] {3133} INFO - iteration 264, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:46] {3313} INFO -  at 33.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:46] {3133} INFO - iteration 265, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:46] {3313} INFO -  at 33.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:46] {3133} INFO - iteration 266, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:47] {3313} INFO -  at 33.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:47] {3133} INFO - iteration 267, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:47] {3313} INFO -  at 33.6s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:47] {3133} INFO - iteration 268, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:47] {3313} INFO -  at 33.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:47] {3133} INFO - iteration 269, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:47] {3313} INFO -  at 33.9s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:47] {3133} INFO - iteration 270, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:47] {3313} INFO -  at 34.0s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:47] {3133} INFO - iteration 271, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:47] {3313} INFO -  at 34.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:47] {3133} INFO - iteration 272, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:47] {3313} INFO -  at 34.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:47] {3133} INFO - iteration 273, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:47] {3313} INFO -  at 34.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:47] {3133} INFO - iteration 274, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:48] {3313} INFO -  at 34.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:48] {3133} INFO - iteration 275, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:48] {3313} INFO -  at 34.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:48] {3133} INFO - iteration 276, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:48] {3313} INFO -  at 34.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:48] {3133} INFO - iteration 277, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:48] {3313} INFO -  at 34.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:48] {3133} INFO - iteration 278, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:48] {3313} INFO -  at 35.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:48] {3133} INFO - iteration 279, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:48] {3313} INFO -  at 35.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:48] {3133} INFO - iteration 280, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:48] {3313} INFO -  at 35.3s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:48] {3133} INFO - iteration 281, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:48] {3313} INFO -  at 35.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:54:48] {3133} INFO - iteration 282, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:49] {3313} INFO -  at 35.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:49] {3133} INFO - iteration 283, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:49] {3313} INFO -  at 35.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:49] {3133} INFO - iteration 284, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:49] {3313} INFO -  at 35.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:49] {3133} INFO - iteration 285, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:49] {3313} INFO -  at 35.9s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:49] {3133} INFO - iteration 286, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:49] {3313} INFO -  at 36.0s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:49] {3133} INFO - iteration 287, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:49] {3313} INFO -  at 36.2s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:49] {3133} INFO - iteration 288, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:49] {3313} INFO -  at 36.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:49] {3133} INFO - iteration 289, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:50] {3313} INFO -  at 36.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:50] {3133} INFO - iteration 290, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:50] {3313} INFO -  at 36.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:50] {3133} INFO - iteration 291, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:50] {3313} INFO -  at 36.7s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:50] {3133} INFO - iteration 292, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:50] {3313} INFO -  at 36.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:50] {3133} INFO - iteration 293, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:50] {3313} INFO -  at 37.0s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:50] {3133} INFO - iteration 294, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:50] {3313} INFO -  at 37.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:50] {3133} INFO - iteration 295, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:50] {3313} INFO -  at 37.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:50] {3133} INFO - iteration 296, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:50] {3313} INFO -  at 37.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:50] {3133} INFO - iteration 297, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:51] {3313} INFO -  at 37.5s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:51] {3133} INFO - iteration 298, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:51] {3313} INFO -  at 37.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:51] {3133} INFO - iteration 299, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:51] {3313} INFO -  at 37.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:51] {3133} INFO - iteration 300, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:51] {3313} INFO -  at 37.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:51] {3133} INFO - iteration 301, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:51] {3313} INFO -  at 37.9s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:51] {3133} INFO - iteration 302, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:51] {3313} INFO -  at 38.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:51] {3133} INFO - iteration 303, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:51] {3313} INFO -  at 38.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:51] {3133} INFO - iteration 304, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:51] {3313} INFO -  at 38.3s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:51] {3133} INFO - iteration 305, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:52] {3313} INFO -  at 38.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:52] {3133} INFO - iteration 306, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:52] {3313} INFO -  at 38.6s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:52] {3133} INFO - iteration 307, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:52] {3313} INFO -  at 38.7s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:52] {3133} INFO - iteration 308, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:52] {3313} INFO -  at 38.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:52] {3133} INFO - iteration 309, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:52] {3313} INFO -  at 39.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:52] {3133} INFO - iteration 310, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:52] {3313} INFO -  at 39.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:52] {3133} INFO - iteration 311, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:52] {3313} INFO -  at 39.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:52] {3133} INFO - iteration 312, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:52] {3313} INFO -  at 39.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:52] {3133} INFO - iteration 313, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:53] {3313} INFO -  at 39.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:53] {3133} INFO - iteration 314, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:53] {3313} INFO -  at 39.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:53] {3133} INFO - iteration 315, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:53] {3313} INFO -  at 39.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:53] {3133} INFO - iteration 316, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:53] {3313} INFO -  at 39.8s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:53] {3133} INFO - iteration 317, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:53] {3313} INFO -  at 39.9s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:53] {3133} INFO - iteration 318, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:53] {3313} INFO -  at 40.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:53] {3133} INFO - iteration 319, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:53] {3313} INFO -  at 40.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:53] {3133} INFO - iteration 320, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:53] {3313} INFO -  at 40.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:53] {3133} INFO - iteration 321, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:53] {3313} INFO -  at 40.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:53] {3133} INFO - iteration 322, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:54] {3313} INFO -  at 40.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:54] {3133} INFO - iteration 323, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:54] {3313} INFO -  at 40.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:54] {3133} INFO - iteration 324, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:54] {3313} INFO -  at 40.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:54] {3133} INFO - iteration 325, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:54] {3313} INFO -  at 40.9s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:54] {3133} INFO - iteration 326, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:54] {3313} INFO -  at 41.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:54] {3133} INFO - iteration 327, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:54] {3313} INFO -  at 41.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:54] {3133} INFO - iteration 328, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:54] {3313} INFO -  at 41.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:54] {3133} INFO - iteration 329, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:54] {3313} INFO -  at 41.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:54] {3133} INFO - iteration 330, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:55] {3313} INFO -  at 41.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:55] {3133} INFO - iteration 331, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:55] {3313} INFO -  at 41.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:55] {3133} INFO - iteration 332, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:55] {3313} INFO -  at 41.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:55] {3133} INFO - iteration 333, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:55] {3313} INFO -  at 41.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:55] {3133} INFO - iteration 334, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:55] {3313} INFO -  at 42.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:55] {3133} INFO - iteration 335, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:55] {3313} INFO -  at 42.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:55] {3133} INFO - iteration 336, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:55] {3313} INFO -  at 42.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:55] {3133} INFO - iteration 337, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:55] {3313} INFO -  at 42.4s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:55] {3133} INFO - iteration 338, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:56] {3313} INFO -  at 42.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:56] {3133} INFO - iteration 339, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:56] {3313} INFO -  at 42.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:56] {3133} INFO - iteration 340, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:56] {3313} INFO -  at 42.7s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:56] {3133} INFO - iteration 341, current learner lgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:54:56] {3313} INFO -  at 42.7s,\testimator lgbm's best error=0.0725,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:56] {3133} INFO - iteration 342, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:56] {3313} INFO -  at 42.9s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:56] {3133} INFO - iteration 343, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:56] {3313} INFO -  at 43.0s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:56] {3133} INFO - iteration 344, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:56] {3313} INFO -  at 43.2s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:56] {3133} INFO - iteration 345, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:56] {3313} INFO -  at 43.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:56] {3133} INFO - iteration 346, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:57] {3313} INFO -  at 43.4s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:57] {3133} INFO - iteration 347, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:57] {3313} INFO -  at 43.6s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:57] {3133} INFO - iteration 348, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:57] {3313} INFO -  at 43.7s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:57] {3133} INFO - iteration 349, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:57] {3313} INFO -  at 43.9s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:57] {3133} INFO - iteration 350, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:57] {3313} INFO -  at 44.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:57] {3133} INFO - iteration 351, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:57] {3313} INFO -  at 44.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:57] {3133} INFO - iteration 352, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:57] {3313} INFO -  at 44.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:57] {3133} INFO - iteration 353, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:57] {3313} INFO -  at 44.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:57] {3133} INFO - iteration 354, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:58] {3313} INFO -  at 44.5s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:54:58] {3133} INFO - iteration 355, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:58] {3313} INFO -  at 44.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:58] {3133} INFO - iteration 356, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:58] {3313} INFO -  at 44.8s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:58] {3133} INFO - iteration 357, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:58] {3313} INFO -  at 44.9s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:58] {3133} INFO - iteration 358, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:58] {3313} INFO -  at 45.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:58] {3133} INFO - iteration 359, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:58] {3313} INFO -  at 45.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:58] {3133} INFO - iteration 360, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:58] {3313} INFO -  at 45.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:58] {3133} INFO - iteration 361, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:59] {3313} INFO -  at 45.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:59] {3133} INFO - iteration 362, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:59] {3313} INFO -  at 45.6s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:59] {3133} INFO - iteration 363, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:59] {3313} INFO -  at 45.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:59] {3133} INFO - iteration 364, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:59] {3313} INFO -  at 45.8s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:59] {3133} INFO - iteration 365, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:59] {3313} INFO -  at 46.0s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:59] {3133} INFO - iteration 366, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:59] {3313} INFO -  at 46.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:59] {3133} INFO - iteration 367, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:54:59] {3313} INFO -  at 46.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:59] {3133} INFO - iteration 368, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:54:59] {3313} INFO -  at 46.3s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:54:59] {3133} INFO - iteration 369, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:00] {3313} INFO -  at 46.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:00] {3133} INFO - iteration 370, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:00] {3313} INFO -  at 46.6s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:55:00] {3133} INFO - iteration 371, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:00] {3313} INFO -  at 46.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:00] {3133} INFO - iteration 372, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:00] {3313} INFO -  at 46.8s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:00] {3133} INFO - iteration 373, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:00] {3313} INFO -  at 47.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:00] {3133} INFO - iteration 374, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:00] {3313} INFO -  at 47.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:00] {3133} INFO - iteration 375, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:00] {3313} INFO -  at 47.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:00] {3133} INFO - iteration 376, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:00] {3313} INFO -  at 47.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:00] {3133} INFO - iteration 377, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:00] {3313} INFO -  at 47.4s,\testimator lgbm's best error=0.0725,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:00] {3133} INFO - iteration 378, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:01] {3313} INFO -  at 47.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:01] {3133} INFO - iteration 379, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:01] {3313} INFO -  at 47.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:01] {3133} INFO - iteration 380, current learner xgboost\n",
      "[flaml.automl: 08-30 11:55:01] {3313} INFO -  at 47.7s,\testimator xgboost's best error=0.0712,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:01] {3133} INFO - iteration 381, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:01] {3313} INFO -  at 47.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:01] {3133} INFO - iteration 382, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:01] {3313} INFO -  at 47.9s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:01] {3133} INFO - iteration 383, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:01] {3313} INFO -  at 48.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:01] {3133} INFO - iteration 384, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:01] {3313} INFO -  at 48.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:01] {3133} INFO - iteration 385, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:01] {3313} INFO -  at 48.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:01] {3133} INFO - iteration 386, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:02] {3313} INFO -  at 48.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:02] {3133} INFO - iteration 387, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:02] {3313} INFO -  at 48.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:02] {3133} INFO - iteration 388, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:02] {3313} INFO -  at 48.7s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:02] {3133} INFO - iteration 389, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:02] {3313} INFO -  at 48.9s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:02] {3133} INFO - iteration 390, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:02] {3313} INFO -  at 49.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:02] {3133} INFO - iteration 391, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:02] {3313} INFO -  at 49.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:02] {3133} INFO - iteration 392, current learner xgb_limitdepth\n",
      "[flaml.automl: 08-30 11:55:02] {3313} INFO -  at 49.3s,\testimator xgb_limitdepth's best error=0.0646,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:02] {3133} INFO - iteration 393, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:02] {3313} INFO -  at 49.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:02] {3133} INFO - iteration 394, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:03] {3313} INFO -  at 49.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:03] {3133} INFO - iteration 395, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:03] {3313} INFO -  at 49.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:03] {3133} INFO - iteration 396, current learner extra_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:55:03] {3313} INFO -  at 49.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:03] {3133} INFO - iteration 397, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:03] {3313} INFO -  at 49.9s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:03] {3133} INFO - iteration 398, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:03] {3313} INFO -  at 50.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:03] {3133} INFO - iteration 399, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:03] {3313} INFO -  at 50.1s,\testimator lgbm's best error=0.0725,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:03] {3133} INFO - iteration 400, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:03] {3313} INFO -  at 50.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:03] {3133} INFO - iteration 401, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:03] {3313} INFO -  at 50.4s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:03] {3133} INFO - iteration 402, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:04] {3313} INFO -  at 50.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:04] {3133} INFO - iteration 403, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:04] {3313} INFO -  at 50.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:04] {3133} INFO - iteration 404, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:04] {3313} INFO -  at 50.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:04] {3133} INFO - iteration 405, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:04] {3313} INFO -  at 50.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:04] {3133} INFO - iteration 406, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:04] {3313} INFO -  at 50.9s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:04] {3133} INFO - iteration 407, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:04] {3313} INFO -  at 51.1s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:04] {3133} INFO - iteration 408, current learner xgboost\n",
      "[flaml.automl: 08-30 11:55:04] {3313} INFO -  at 51.1s,\testimator xgboost's best error=0.0712,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:04] {3133} INFO - iteration 409, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:04] {3313} INFO -  at 51.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:04] {3133} INFO - iteration 410, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:05] {3313} INFO -  at 51.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:05] {3133} INFO - iteration 411, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:05] {3313} INFO -  at 51.6s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:05] {3133} INFO - iteration 412, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:05] {3313} INFO -  at 51.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:05] {3133} INFO - iteration 413, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:05] {3313} INFO -  at 51.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:05] {3133} INFO - iteration 414, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:05] {3313} INFO -  at 51.9s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:55:05] {3133} INFO - iteration 415, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:05] {3313} INFO -  at 52.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:05] {3133} INFO - iteration 416, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:05] {3313} INFO -  at 52.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:05] {3133} INFO - iteration 417, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:05] {3313} INFO -  at 52.3s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:05] {3133} INFO - iteration 418, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:06] {3313} INFO -  at 52.4s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:06] {3133} INFO - iteration 419, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:06] {3313} INFO -  at 52.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:06] {3133} INFO - iteration 420, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:06] {3313} INFO -  at 52.7s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:06] {3133} INFO - iteration 421, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:06] {3313} INFO -  at 52.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:06] {3133} INFO - iteration 422, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:06] {3313} INFO -  at 53.0s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:06] {3133} INFO - iteration 423, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:06] {3313} INFO -  at 53.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:06] {3133} INFO - iteration 424, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:06] {3313} INFO -  at 53.3s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:06] {3133} INFO - iteration 425, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 53.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 426, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 53.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 427, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 53.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 428, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 53.7s,\testimator lgbm's best error=0.0686,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 429, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 53.7s,\testimator lgbm's best error=0.0686,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 430, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 53.7s,\testimator lgbm's best error=0.0686,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 431, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 53.8s,\testimator lgbm's best error=0.0686,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 432, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 53.8s,\testimator lgbm's best error=0.0686,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 433, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 53.8s,\testimator lgbm's best error=0.0686,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 434, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 53.9s,\testimator lgbm's best error=0.0673,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 435, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 53.9s,\testimator lgbm's best error=0.0673,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 436, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 54.0s,\testimator lgbm's best error=0.0673,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 437, current learner lgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 54.0s,\testimator lgbm's best error=0.0673,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 438, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 54.0s,\testimator lgbm's best error=0.0620,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 439, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 54.1s,\testimator lgbm's best error=0.0620,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 440, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 54.1s,\testimator lgbm's best error=0.0620,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 441, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 54.2s,\testimator lgbm's best error=0.0620,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 442, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 54.2s,\testimator lgbm's best error=0.0620,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 443, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 54.3s,\testimator lgbm's best error=0.0620,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 444, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 54.3s,\testimator lgbm's best error=0.0620,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 445, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 54.3s,\testimator lgbm's best error=0.0620,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 446, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:07] {3313} INFO -  at 54.4s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:07] {3133} INFO - iteration 447, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:08] {3313} INFO -  at 54.4s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:08] {3133} INFO - iteration 448, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:08] {3313} INFO -  at 54.5s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:08] {3133} INFO - iteration 449, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:08] {3313} INFO -  at 54.5s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:08] {3133} INFO - iteration 450, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:08] {3313} INFO -  at 54.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:08] {3133} INFO - iteration 451, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:08] {3313} INFO -  at 54.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:08] {3133} INFO - iteration 452, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:08] {3313} INFO -  at 54.8s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:08] {3133} INFO - iteration 453, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:08] {3313} INFO -  at 54.9s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:08] {3133} INFO - iteration 454, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:08] {3313} INFO -  at 54.9s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:08] {3133} INFO - iteration 455, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:08] {3313} INFO -  at 55.0s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:08] {3133} INFO - iteration 456, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:08] {3313} INFO -  at 55.0s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:08] {3133} INFO - iteration 457, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:08] {3313} INFO -  at 55.1s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:08] {3133} INFO - iteration 458, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:08] {3313} INFO -  at 55.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:08] {3133} INFO - iteration 459, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:08] {3313} INFO -  at 55.3s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:08] {3133} INFO - iteration 460, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:08] {3313} INFO -  at 55.4s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:08] {3133} INFO - iteration 461, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:09] {3313} INFO -  at 55.4s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:09] {3133} INFO - iteration 462, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:09] {3313} INFO -  at 55.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:09] {3133} INFO - iteration 463, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:09] {3313} INFO -  at 55.6s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:09] {3133} INFO - iteration 464, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:09] {3313} INFO -  at 55.6s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:09] {3133} INFO - iteration 465, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:09] {3313} INFO -  at 55.7s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:09] {3133} INFO - iteration 466, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:09] {3313} INFO -  at 55.7s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:09] {3133} INFO - iteration 467, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:09] {3313} INFO -  at 55.9s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:09] {3133} INFO - iteration 468, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:09] {3313} INFO -  at 55.9s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:09] {3133} INFO - iteration 469, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:09] {3313} INFO -  at 56.0s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:09] {3133} INFO - iteration 470, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:09] {3313} INFO -  at 56.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:55:09] {3133} INFO - iteration 471, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:09] {3313} INFO -  at 56.2s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:09] {3133} INFO - iteration 472, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:09] {3313} INFO -  at 56.3s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:09] {3133} INFO - iteration 473, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:10] {3313} INFO -  at 56.4s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:10] {3133} INFO - iteration 474, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:10] {3313} INFO -  at 56.5s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:10] {3133} INFO - iteration 475, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:10] {3313} INFO -  at 56.5s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:10] {3133} INFO - iteration 476, current learner xgb_limitdepth\n",
      "[flaml.automl: 08-30 11:55:10] {3313} INFO -  at 56.6s,\testimator xgb_limitdepth's best error=0.0646,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:10] {3133} INFO - iteration 477, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:10] {3313} INFO -  at 56.7s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:10] {3133} INFO - iteration 478, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:10] {3313} INFO -  at 56.7s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:10] {3133} INFO - iteration 479, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:10] {3313} INFO -  at 56.8s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:10] {3133} INFO - iteration 480, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:10] {3313} INFO -  at 57.0s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:10] {3133} INFO - iteration 481, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:10] {3313} INFO -  at 57.0s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:10] {3133} INFO - iteration 482, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:10] {3313} INFO -  at 57.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:10] {3133} INFO - iteration 483, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:10] {3313} INFO -  at 57.2s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:10] {3133} INFO - iteration 484, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:10] {3313} INFO -  at 57.2s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:10] {3133} INFO - iteration 485, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:10] {3313} INFO -  at 57.3s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:10] {3133} INFO - iteration 486, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:10] {3313} INFO -  at 57.3s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:10] {3133} INFO - iteration 487, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:11] {3313} INFO -  at 57.5s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:11] {3133} INFO - iteration 488, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:11] {3313} INFO -  at 57.5s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:11] {3133} INFO - iteration 489, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:11] {3313} INFO -  at 57.7s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:11] {3133} INFO - iteration 490, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:11] {3313} INFO -  at 57.7s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:11] {3133} INFO - iteration 491, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:11] {3313} INFO -  at 57.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:11] {3133} INFO - iteration 492, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:11] {3313} INFO -  at 57.9s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:11] {3133} INFO - iteration 493, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:11] {3313} INFO -  at 57.9s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:11] {3133} INFO - iteration 494, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:11] {3313} INFO -  at 58.1s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:11] {3133} INFO - iteration 495, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:11] {3313} INFO -  at 58.1s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:11] {3133} INFO - iteration 496, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:11] {3313} INFO -  at 58.2s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:11] {3133} INFO - iteration 497, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:11] {3313} INFO -  at 58.3s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 08-30 11:55:11] {3133} INFO - iteration 498, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:11] {3313} INFO -  at 58.4s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:12] {3133} INFO - iteration 499, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:12] {3313} INFO -  at 58.4s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:12] {3133} INFO - iteration 500, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:12] {3313} INFO -  at 58.5s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:12] {3133} INFO - iteration 501, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:12] {3313} INFO -  at 58.7s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:12] {3133} INFO - iteration 502, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:12] {3313} INFO -  at 58.8s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:12] {3133} INFO - iteration 503, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:12] {3313} INFO -  at 59.0s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:12] {3133} INFO - iteration 504, current learner lrl1\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[flaml.automl: 08-30 11:55:12] {3313} INFO -  at 59.1s,\testimator lrl1's best error=0.0593,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:12] {3133} INFO - iteration 505, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:12] {3313} INFO -  at 59.2s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:12] {3133} INFO - iteration 506, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:12] {3313} INFO -  at 59.2s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:12] {3133} INFO - iteration 507, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:12] {3313} INFO -  at 59.3s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:12] {3133} INFO - iteration 508, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:12] {3313} INFO -  at 59.3s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:12] {3133} INFO - iteration 509, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:12] {3313} INFO -  at 59.4s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:12] {3133} INFO - iteration 510, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:13] {3313} INFO -  at 59.4s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:13] {3133} INFO - iteration 511, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:13] {3313} INFO -  at 59.5s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:13] {3133} INFO - iteration 512, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:13] {3313} INFO -  at 59.6s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:13] {3133} INFO - iteration 513, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:13] {3313} INFO -  at 59.7s,\testimator lgbm's best error=0.0606,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:13] {3133} INFO - iteration 514, current learner extra_tree\n",
      "[flaml.automl: 08-30 11:55:13] {3313} INFO -  at 59.8s,\testimator extra_tree's best error=0.0554,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:13] {3133} INFO - iteration 515, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:13] {3313} INFO -  at 59.8s,\testimator lgbm's best error=0.0581,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:13] {3133} INFO - iteration 516, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:13] {3313} INFO -  at 59.9s,\testimator lgbm's best error=0.0581,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:13] {3133} INFO - iteration 517, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:13] {3313} INFO -  at 59.9s,\testimator lgbm's best error=0.0581,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:13] {3133} INFO - iteration 518, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:13] {3313} INFO -  at 60.0s,\testimator lgbm's best error=0.0581,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:13] {3133} INFO - iteration 519, current learner lgbm\n",
      "[flaml.automl: 08-30 11:55:13] {3313} INFO -  at 60.0s,\testimator lgbm's best error=0.0581,\tbest estimator extra_tree's best error=0.0554\n",
      "[flaml.automl: 08-30 11:55:13] {3577} INFO - retrain extra_tree for 0.0s\n",
      "[flaml.automl: 08-30 11:55:13] {3584} INFO - retrained model: ExtraTreesClassifier(criterion='entropy', max_features=0.4790194713813434,\n",
      "                     max_leaf_nodes=20, n_estimators=8, n_jobs=-1)\n",
      "[flaml.automl: 08-30 11:55:13] {2862} INFO - fit succeeded\n",
      "[flaml.automl: 08-30 11:55:13] {2863} INFO - Time taken to find the best model: 14.743628978729248\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "\n",
    "automl_settings = {\n",
    "    \"time_budget\": 60,\n",
    "    \"metric\": 'accuracy',\n",
    "    \"task\": 'classification'\n",
    "}\n",
    "\n",
    "automl = AutoML()\n",
    "automl.fit(X_train = X_train, y_train = y_train, **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88e3965e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but ExtraTreesClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = automl.predict(OG_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "239f6fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9863064201822299"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(OG_y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3bdc6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
